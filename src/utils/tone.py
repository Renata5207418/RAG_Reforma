import re
import unicodedata
import logging
from langchain_openai import ChatOpenAI
from src.config import settings

log = logging.getLogger(__name__)


def detect_tone_local(msg: str) -> str:
    """
    Detecta o tom da mensagem com base em padr√µes, g√≠rias e palavras-chave conhecidas.
    Args:
        msg (str): Texto da pergunta do usu√°rio.
    Returns:
        str:Um dos tons ('irritado e conciso', 'informal e descontra√≠do', 'formal e polido', 'objetivo').
    """
    txt = unicodedata.normalize("NFKD", msg.lower())
    # Irritado
    if re.search(r"!{2,}|[üò°ü§¨ü§Ø]", msg) or any(w in txt for w in (
        "absurdo", "ridiculo", "rid√≠culo", "palha√ßada", "roubo", "nojento", "vergonha", "mentira",
        "mentiroso", "sacanagem", "falta de respeito", "n√£o aguento", "ladr√£o", "indignado"
    )):
        return "irritado e conciso"
    # Informal
    if any(g in txt for g in (
        "mano", "mona", "bixa", "amigo", "amiga", "v√©i", "velho", "cara", "porra", "tipo", "m√≥", "t√¥", "sai fora", "aff", "vish", "top",
        "massa", "zika", "bora", "falae", "tmj", "par√ßa", "kkk", "rs", "meu", "oxe", "v√©a", "v√©io", "kk", "rsrs"
    )):
        return "informal e descontra√≠do"
    # Formal/polido
    if any(w in txt for w in (
        "por favor", "gentileza", "poderia", "agrade√ßo", "cordialmente", "atenciosamente", "fico no aguardo",
        "seria poss√≠vel", "obrigado", "obrigada", "grato", "grata", "gostaria", "aprecio", "sauda√ß√µes"
    )):
        return "formal e polido"
    return "objetivo"


# Fun√ß√£o de detec√ß√£o por LLM (OpenAI)
def detect_tone_llm(msg: str) -> str:
    """
    Usa LLM (OpenAI) para classificar o tom da mensagem quando o m√©todo local n√£o reconhece.
    Args:
        msg (str): Texto da pergunta do usu√°rio.
    Returns:
        str:Um dos tons ('irritado e conciso', 'informal e descontra√≠do', 'formal e polido', 'objetivo').
    """
    llm = ChatOpenAI(
        model=settings.default_model,  # use um modelo leve e barato aqui
        openai_api_key=settings.api_key,
        temperature=0,
        max_tokens=15,
        top_p=1.0,
    )
    prompt = (
        "Classifique o tom da mensagem a seguir como uma das op√ß√µes abaixo, respondendo APENAS com o nome do tom:\n"
        "- irritado e conciso\n"
        "- informal e descontra√≠do\n"
        "- formal e polido\n"
        "- objetivo\n\n"
        "Mensagem: " + msg.strip()
    )
    try:
        result = llm.invoke(prompt).content.strip().lower()
        # Padroniza sa√≠da
        if "irritado" in result:
            return "irritado e conciso"
        if "informal" in result:
            return "informal e descontra√≠do"
        if "formal" in result:
            return "formal e polido"
        return "objetivo"
    except Exception as exc:
        log.warning(f"LLM detect_tone_llm falhou: {exc}")
        return "objetivo"


# Fun√ß√£o principal h√≠brida
def detect_tone(msg: str) -> str:
    """
    Detecta o tom h√≠brido: tenta localmente, depois via LLM se necess√°rio.
    Loga exemplos classificados s√≥ pela LLM.
    Args:
        msg (str): Texto da pergunta do usu√°rio.
    Returns:
        str: Tom detectado.
    """
    tone = detect_tone_local(msg)
    if tone == "objetivo":
        tone_llm = detect_tone_llm(msg)
        if tone_llm != "objetivo":
            with open("logs/tone_llm_cases.txt", "a", encoding="utf-8") as f:
                f.write(f"TOM: {tone_llm.upper()} | MSG: {msg.strip()}\n")
            log.info(f"Tone LLM detectou '{tone_llm}' para: {msg.strip()}")
        return tone_llm
    return tone
